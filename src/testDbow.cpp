#include "Thirdparty/DBoW3/src/DBoW3.h"
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/features2d/features2d.hpp>
#include <iostream>
#include <vector>
#include <string>
#include <opencv2/imgproc.hpp>
#include "Extractors/SPextractor.h"
#include "Matchers/SPmatcher.h"
#include "Tracking.h"
#include "chrono"


using namespace ORB_SLAM3;
using namespace cv;
using namespace std;
cv::Mat bindesc(cv::Mat desc){
    cv::Mat descriptors_converted = cv::Mat(desc.size(), CV_8UC1);
    for(size_t i = 0; i<desc.rows; ++i)
    {
        cv::Mat tmp;
        cv::threshold(desc.row(i), tmp, 0, 1, cv::THRESH_BINARY);
        for(size_t j = 0; j<desc.cols; j++)
        {
            descriptors_converted.at<uchar>(i,j) = tmp.at<float>(j);
        }
    }
    return descriptors_converted;
}   
vector<cv::DMatch> SearchByBoW(cv::Mat desc1,cv::Mat desc2, DBoW3::FeatureVector FeatVec1, DBoW3::FeatureVector FeatVec2);

int testDbow(){
    DBoW3::Vocabulary* vocab = new DBoW3::Vocabulary();
    vocab->load("/media/xiao/data3/learning-slam/SP-Loop/support_files/voc_binary_tartan_8u_6.yml.gz");
    SPextractor *mpExtractorLeft = new SPextractor(500,1,1,20,7);
    // SPmatcher* spMatcher = new SPmatcher(0.9);
    // spMatcher->MatchingPoints()
    // read the images and database  
    cout << "reading database" << endl;
    //DBoW3::Vocabulary vocab("/media/xiao/data3/learning-slam/ORB_SLAM3_detailed_comments/Vocabulary/superpoint_voc.yml.gz");
    // DBoW3::Vocabulary vocab("./vocab_larger.yml.gz");  // use large vocab if you want: 
    if (vocab->empty()) {
        cerr << "Vocabulary does not exist." << endl;
        return 1;
    }
    cout << "reading images... " << endl;
    vector<Mat> images;
    for (int i = 0; i < 19; i++) {
        string path = "/media/xiao/data3/learning-slam/slambook2/ch11/data/" + to_string(i + 1) + ".png";
        cv::Mat gray_image;
        cv::cvtColor(imread(path), gray_image, cv::COLOR_BGR2GRAY);
        images.push_back(gray_image);
    }

    // NOTE: in this case we are comparing images with a vocabulary generated by themselves, this may lead to overfit.
    // detect ORB features
    cout << "detecting ORB features ... " << endl;
    Ptr<Feature2D> detector = ORB::create();
    vector<Mat> descriptors;


    for (Mat &image:images) {
        cout<<image.type()<<endl;
        vector<KeyPoint> keypoints;
        Mat descriptor;
        int monoLeft = (*mpExtractorLeft)(image,keypoints, descriptor);//superpoint特征点
        //detector->detectAndCompute(image, Mat(), keypoints, descriptor);//orb特征点
        cv::Mat descriptors_converted = cv::Mat(descriptor.size(), CV_8UC1);
        for(size_t i = 0; i<descriptor.rows; ++i)
        {
            cv::Mat tmp;
            cv::threshold(descriptor.row(i), tmp, 0, 1, cv::THRESH_BINARY);
            for(size_t j = 0; j<descriptor.cols; j++)
            {
                descriptors_converted.at<uchar>(i,j) = tmp.at<float>(j);
            }
        }
        descriptors.push_back(descriptors_converted);
    }

    // we can compare the images directly or we can compare one image to a database 
    // images :
    cout << "comparing images with images " << endl;
    for (int im = 0; im < images.size(); im++) {
        DBoW3::BowVector v1;
        DBoW3::FeatureVector f1;
        // cv::Mat randomMat(500, 256, CV_32F);
        // cv::randu(randomMat, cv::Scalar(0), cv::Scalar(1));
        std::vector<cv::Mat> vDesc;
        vDesc.reserve(descriptors[im].rows);
        for (int j=0;j<descriptors[im].rows;j++)
            vDesc.push_back(descriptors[im].row(j));
        vocab->transform(vDesc, v1, f1,4);
        //vocab->transform(descriptors[im], v1);
        for (int j = im; j < images.size(); j++) {
            DBoW3::BowVector v2;
            vocab->transform(descriptors[j], v2);
            double score = vocab->score(v1, v2);
            cout << "image " << im+1 << " vs image " << j+1 << " : " << score << endl;
        }
        cout << endl;
    }

    // or with database 
    cout << "comparing images with database " << endl;
    DBoW3::Database db(*vocab, false, 0);
    for (int i = 0; i < descriptors.size(); i++)
        db.add(descriptors[i]);
    cout << "database info: " << db << endl;
    for (int i = 0; i < descriptors.size(); i++) {
        DBoW3::QueryResults ret;
        db.query(descriptors[i], ret, 4);      // max result=4
        cout << "searching for image " << i << " returns " << ret << endl << endl;
    }
    cout << "done." << endl;
}

int testmatcherBow(){

    DBoW3::Vocabulary* vocab = new DBoW3::Vocabulary();
    vocab->load("/media/xiao/data3/learning-slam/SP-Loop/support_files/voc_binary_tartan_8u_6.yml.gz");
    SPextractor *mpExtractorLeft = new SPextractor(500,1,1,20,7);

    // read the images and database  
    cout << "reading database" << endl;
    //DBoW3::Vocabulary vocab("/media/xiao/data3/learning-slam/ORB_SLAM3_detailed_comments/Vocabulary/superpoint_voc.yml.gz");
    // DBoW3::Vocabulary vocab("./vocab_larger.yml.gz");  // use large vocab if you want: 
    if (vocab->empty()) {
        cerr << "Vocabulary does not exist." << endl;
        return 1;
    }
    cout << "reading images... " << endl;

    string path1 = "/media/xiao/data3/slamdataset/euroc/MH05/mav0/cam0/data/1403638580927829504.png";
    string path2 = "/media/xiao/data3/slamdataset/euroc/MH05/mav0/cam0/data/1403638581727829504.png";
    //string path1 = "/media/xiao/data3/slamdataset/euroc/MH04/mav0/cam0/data/1403638131095097088.png";
    //string path2 = "/media/xiao/data3/slamdataset/euroc/MH04/mav0/cam0/data/1403638131095097088.png";
    cv::Mat img1,img2;
    cv::cvtColor(imread(path1), img1, cv::COLOR_BGR2GRAY);
    cv::cvtColor(imread(path2), img2, cv::COLOR_BGR2GRAY);
    vector<KeyPoint> kpts1,kpts2;
    cv::Mat desc1_ori,desc2_ori;
    //const cv::Mat desc2_0 = desc2_ori;
    int monoLeft1 = (*mpExtractorLeft)(img1,kpts1, desc1_ori);
    int monoLeft2 = (*mpExtractorLeft)(img2,kpts2, desc2_ori);
    cv::Mat image_with_keypoints;
    cv::drawKeypoints(img1, kpts1, image_with_keypoints, cv::Scalar::all(-1), cv::DrawMatchesFlags::DRAW_RICH_KEYPOINTS);
       cv::imshow("Image with Keypoints", image_with_keypoints);
    cv::waitKey(0);
    const std::vector<cv::KeyPoint> kpts2_c = kpts2;
    const std::vector<cv::KeyPoint> kpts1_c = kpts1;
    const cv::Mat desc2_c = desc2_ori;
    const cv::Mat desc1_c = desc1_ori;
    SPmatcher* spMatcher = new SPmatcher(0.2);
    std::vector<int> vnMatches12 = std::vector<int>(kpts1.size(), -1);
    //std::vector<int> matches12(kpts1.size(),-1);
    //int nmatches = spMatcher->MatchingPoints(kpts1_c, kpts2_c,desc1_c,desc2_c ,vnMatches12);


    vnMatches12.resize(kpts1.size(),-1);
    int rows = 512;//需要修改！
    int cols = 640;
    std::vector<cv::Point2f> kpts_pf0, kpts_pf1;
    for(const cv::KeyPoint& keypoint : kpts1){
        kpts_pf0.emplace_back(keypoint.pt);
    }

    for(const cv::KeyPoint& keypoint : kpts2){
        kpts_pf1.emplace_back(keypoint.pt);
    }
    auto normal_kpts0 = spMatcher->featureMatcher->Matcher_PreProcess(kpts1 , rows , cols);
    auto normal_kpts1 = spMatcher->featureMatcher->Matcher_PreProcess(kpts2 , rows , cols);

    int rows0 = desc1_ori.rows;
    int cols0 = desc2_ori.cols;
    float* descriptors_data0 = new float[rows0 * cols0];
    for (int i = 0 ; i < rows0; i++){
        const float* row_data = desc1_ori.ptr<float>(i);
        for (int j = 0; j < cols0; j++){
            descriptors_data0[i*cols0 + j] = row_data[j];
        }
    }

    int rows1 = desc2_ori.rows;
    int cols1 = desc2_ori.cols;
    float* descriptors_data1 = new float[rows1 * cols1];
    for (int i = 0 ; i < rows1; i++){
        const float* row_data = desc2_ori.ptr<float>(i);
        for (int j = 0; j < cols1; j++){
            descriptors_data1[i*cols1 + j] = row_data[j];
        }
    }

    Configuration cfg;
    std::vector<Ort::Value> output = spMatcher->featureMatcher->Matcher_Inference(normal_kpts0, normal_kpts1, descriptors_data0, descriptors_data1);
    //std::pair<std::vector<cv::Point2f>, std::vector<cv::Point2f>> output_end;
    int size;
    // std::vector<int> vnMatches12;
    // vnMatches12 = std::vector<int>(normal_kpts0.size(), -1);
    size = spMatcher->featureMatcher->Matcher_PostProcess_fused(output, kpts_pf0 , kpts_pf1, vnMatches12);
    cout<<"size: "<<size<<endl;
    vector<cv::DMatch> vmatches;
    for(int i=0 ; i < vnMatches12.size(); i++)
    {
        int idx = vnMatches12[i];
        if(idx > 0)
        {
            cv::DMatch match;
            match.queryIdx = i;
            match.trainIdx = idx;
            vmatches.push_back(match);
        }
    }
    cv::Mat matched_img;
    cv::drawMatches(img1,kpts1,img2,kpts2,vmatches,matched_img, cv::Scalar(0, 255, 0));
    cv::imshow("Matched Features", matched_img);
    cv::waitKey(0);




    cv::Mat desc1 = bindesc(desc1_ori);
    cv::Mat desc2 = bindesc(desc2_ori);
    
    DBoW3::BowVector v1,v2;
    DBoW3::FeatureVector f1,f2;
    std::vector<cv::Mat> vDesc1,vDesc2;
    for (int j=0;j<desc1.rows;j++)
        vDesc1.push_back(desc1.row(j));
    for(int j=0;j<desc2.rows;j++)
        vDesc2.push_back(desc2.row(j));
    vocab->transform(vDesc1, v1, f1,4);
    vocab->transform(vDesc2, v2, f2,4);
    double score = vocab->score(v1, v2);
    cout<<"score: "<<score<<endl;
    auto start_time = std::chrono::high_resolution_clock::now();
    vector<DMatch> vmatcher = SearchByBoW(desc1_ori,desc2_ori,f1,f2);
    auto end_time = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
    std::cout << "程序运行时间: " << duration.count() << " 毫秒" << std::endl;
    //cv::Mat matched_img;
    cv::drawMatches(img1,kpts1,img2,kpts2,vmatcher,matched_img,cv::Scalar(0, 255, 0));
    cv::imshow("Matched Features", matched_img);
    cv::waitKey(0);
    // for(int i = 0 ; i < vmatcher.size(); i++)
    // {
    //     cout<<vmatcher[i]<<" ";
    // }
    cout<<endl;
    
}
void plotspmatch(cv::Mat frame1, std::vector<cv::KeyPoint> kpts1, std::vector<cv::KeyPoint> kpts2, cv::Mat frame2, std::vector<int> vmatches12){
    vector<cv::DMatch> vmatches;
    for(int i=0 ; i < vmatches12.size(); i++)
    {
        int idx = vmatches12[i];
        if(idx > 0)
        {
            cv::DMatch match;
            match.queryIdx = i;
            match.trainIdx = idx;
            vmatches.push_back(match);
        }
    }
    cv::Mat matched_img;
    cv::drawMatches(frame1,kpts1,frame2,kpts2,vmatches,matched_img);
    cv::imshow("Matched Features", matched_img);
    cv::waitKey(0);

}
/***************************************************
 * 本节演示了如何根据前面训练的字典计算相似性评分
 * ************************************************/
int main(int argc, char **argv) {
    //testDbow();
    testmatcherBow();
    return 1;
}
vector<cv::DMatch> SearchByBoW(cv::Mat desc1,cv::Mat desc2, DBoW3::FeatureVector FeatVec1, DBoW3::FeatureVector FeatVec2)
{
    vector<cv::DMatch> matches;
    DBoW3::FeatureVector::const_iterator f1it = FeatVec1.begin();
    DBoW3::FeatureVector::const_iterator f2it = FeatVec2.begin();
    DBoW3::FeatureVector::const_iterator f1end = FeatVec1.end();
    DBoW3::FeatureVector::const_iterator f2end = FeatVec2.end();
    vector<int> vmatcher(desc1.rows, -1);

    while(f1it != f1end && f2it != f2end)
    {
        if(f1it->first == f2it->first)
        {
            for(size_t i1=0, iend1=f1it->second.size(); i1<iend1; i1++)
            {
                const size_t idx1 = f1it->second[i1];
                const cv::Mat &d1 = desc1.row(idx1);
                float bestDist1=256;
                int bestIdx2 =-1;
                float bestDist2=256;
                
                for(size_t i2=0, iend2=f2it->second.size(); i2<iend2; i2++)
                {
                    const size_t idx2 = f2it->second[i2];
                    const cv::Mat &d2 = desc2.row(idx2);
                    float dist = (float)cv::norm(d1 , d2, cv::NORM_L2);
                    if(dist<bestDist1)
                    {
                        bestDist2=bestDist1;
                        bestDist1=dist;
                        bestIdx2=idx2;
                    }
                    else if(dist<bestDist2)
                    {
                        bestDist2 = dist;
                    }
                }
                if(bestDist1 < 0.3)
                {
                    //cout<<"bestDist1: "<<bestDist1<<"bestDist2: "<<bestDist2<<endl;
                    if(static_cast<float>(bestDist1)<0.5*static_cast<float>(bestDist2))
                    {
                        vmatcher[idx1]= bestIdx2;
                    }
                    cv::DMatch match;
                    match.queryIdx = idx1;
                    match.trainIdx = bestIdx2;
                    match.distance = bestDist1;
                    matches.push_back(match);
                }
            }
            f1it++;
            f2it++;

        }
        else if(f1it->first < f2it->first)
        {
            f1it = FeatVec1.lower_bound(f2it->first);
        }
        else
        {
            f2it = FeatVec2.lower_bound(f1it->first);
        }

    }
    return matches;

}